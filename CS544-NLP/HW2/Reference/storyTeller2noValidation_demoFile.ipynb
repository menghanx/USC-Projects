{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbs4k0MJifjA"
   },
   "outputs": [],
   "source": [
    "#read-PDF imports here\n",
    "!pip install PyPDF2\n",
    "import PyPDF2\n",
    "\n",
    "#pre-processing imports here\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 22632,
     "status": "ok",
     "timestamp": 1603005660793,
     "user": {
      "displayName": "Python Simplified",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-cjP-_1ESwkpGiDhXCJp3kOwzBN0UNevCALxWhg=s64",
      "userId": "05471425677068167747"
     },
     "user_tz": 420
    },
    "id": "qBKuc_dR-Fgt",
    "outputId": "8596c2c2-8354-4525-ae17-ec09b646c281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mount Google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhwcUudNChx8"
   },
   "outputs": [],
   "source": [
    "#file locations on drive\n",
    "grimm_url = '/content/drive/My Drive/Lessons/storyTeller/FairytalesByTheBrothersGrimm.txt'\n",
    "coraline_url = '/content/drive/My Drive/Lessons/storyTeller/Coraline.pdf'\n",
    "alice_url = '/content/drive/My Drive/Lessons/storyTeller/AlicesAdvanturesInWonderland.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIIx1pysjBnD"
   },
   "outputs": [],
   "source": [
    "#load punctuation symbols\n",
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r7JQDi3iz14"
   },
   "source": [
    "# **Pre-processing Coraline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vand5igZEP5l"
   },
   "outputs": [],
   "source": [
    "#a function to pre process Coraline by Neil Gaiman\n",
    "\n",
    "def preprocess_coraline(book):\n",
    "  '''\n",
    "  param book: url od a PDF book file\n",
    "  '''\n",
    "  output = \"\"\n",
    "  data = open(book, 'rb')\n",
    "  data = PyPDF2.PdfFileReader(book)\n",
    "  npages = data.getNumPages()\n",
    "  for i in range(npages):\n",
    "    page_i = data.getPage(i).extractText()\n",
    "    output += page_i\n",
    "  output = output[1227:]\n",
    "  output = output.lower()\n",
    "  for word in output:\n",
    "    for char in word:\n",
    "        if char in punct:\n",
    "            word = word.replace(char, \"\")\n",
    "  remove_punct = \"\".join([word for word in output if word not in punct])\n",
    "  processed = word_tokenize(remove_punct)\n",
    "  print('Coraline database includes {} tokens, and {} unique tokens after editing'.format(len(processed), len(set(processed)))) \n",
    "  return processed\n",
    "\n",
    "coraline = preprocess_coraline(coraline_url) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRDl2y87jh1w"
   },
   "source": [
    "## **Preprocessing Alice in Wonderland**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6xyaeRuiMnk"
   },
   "outputs": [],
   "source": [
    "#a function to pre process Alice's Advantures in Wonderland by Lewis Carroll\n",
    "\n",
    "def load_alice(text_file, punct, not_a_word):\n",
    "    '''\n",
    "    param text_file: url to Project Gutenberg's text file for Alice's Advantures in Wonderland by Lewis Carroll\n",
    "    param punct: a string of punctuation characters we'd like to filter\n",
    "    param not_a_word: a list of words we'd like to filter\n",
    "    '''\n",
    "    book = open(text_file, 'r')\n",
    "    book = book.read()\n",
    "    book = book[715:145060]\n",
    "    book_edit = re.sub('[+]', '', book)\n",
    "    book_edit = re.sub(r'(CHAPTER \\w+.\\s)', '', book)\n",
    "    words = word_tokenize(book_edit.lower())\n",
    "    \n",
    "    word_list = []\n",
    "    \n",
    "    # filtering punctuation and non-words\n",
    "    for word in words:\n",
    "        for char in word:\n",
    "            if char in punct:\n",
    "                word = word.replace(char, \"\")\n",
    "        if word not in punct and word not in not_a_word:\n",
    "            word_list.append(word)\n",
    "\n",
    "    print('Alice database includes {} tokens, and {} unique tokens after editing'.format(len(word_list), len(set(word_list)))) \n",
    "    return word_list\n",
    "\n",
    "alice = load_alice(alice_url, (punct.replace('-', \"\") + '’' + '‘'), ['s', '--', 'nt', 've', 'll', 'd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HcUOknolEWm"
   },
   "source": [
    "# **Preprocessing Grimm**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTG-MTfsEgNu"
   },
   "outputs": [],
   "source": [
    "def load_fairytales(text_file):\n",
    "    '''\n",
    "    param text_file: url to Project Gutenberg's text file for Fairytales by The Brothers Grimm\n",
    "    '''\n",
    "    book = open(text_file, encoding='cp1252')\n",
    "    book = book.read()\n",
    "    book = book[2376:519859]\n",
    "    book_edit = re.sub('[(+*)]', '', book)\n",
    "    words = word_tokenize(book_edit.lower())\n",
    "\n",
    "    # filtering punctuation inside tokens (example: didn't or wow!)\n",
    "    for word in words:\n",
    "        for char in word:\n",
    "            if char in punct:\n",
    "                word = word.replace(char, \"\")\n",
    "\n",
    "    # filtering punctuation as alone standing tokens(example: \\ or ,)\n",
    "    words = [word for word in words if word not in punct]\n",
    "\n",
    "    print('Fairytales database includes {} tokens, and {} unique tokens after editing'.format(len(words), len(set(words))))            \n",
    "    return words\n",
    "\n",
    "brothers_grimm = load_fairytales(grimm_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM8boZfBhTaw"
   },
   "source": [
    "# **Combined database including all books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROjnov9uWSbe"
   },
   "outputs": [],
   "source": [
    "data = coraline + alice + brothers_grimm\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84kEdfzunnVY"
   },
   "source": [
    "# **Convert Data into Numeric Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NH5YsCDlm6jq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_IEytwGn0jC"
   },
   "source": [
    "# **Batching Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lP5qnVKWn5gW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lU2YCOBVn6RU"
   },
   "source": [
    "# **Defining the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3008,
     "status": "ok",
     "timestamp": 1603005537546,
     "user": {
      "displayName": "Python Simplified",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-cjP-_1ESwkpGiDhXCJp3kOwzBN0UNevCALxWhg=s64",
      "userId": "05471425677068167747"
     },
     "user_tz": 420
    },
    "id": "uMpb7olaoASw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqcBctDGoA_5"
   },
   "source": [
    "# **Defining Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gj_jF78uoGqy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kc2ysQGoJZU"
   },
   "source": [
    "# **Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUYN20PVoMvn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwNuUJFuoO7k"
   },
   "source": [
    "# **Save Checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUy3YfBxoRZW"
   },
   "outputs": [],
   "source": [
    "checkpoint_url = '/content/drive/My Drive/Lessons/storyTeller/checkpoint3.pth'\n",
    "\n",
    "checkpoint = {'model': model,\n",
    "              'state_dict': model.state_dict(),\n",
    "              'word_to_index': word_to_index,\n",
    "              'index_to_word': {i: word for i, word in enumerate(vocab)},\n",
    "              'epochs': epochs,\n",
    "              'average_loss': average_loss,\n",
    "              'device': device,\n",
    "              'optimizer_state': optimizer.state_dict(),\n",
    "              'batch_size': batch_size}\n",
    "\n",
    "torch.save(checkpoint, checkpoint_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DyoYf0qT__G"
   },
   "source": [
    "# **Load Checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "executionInfo": {
     "elapsed": 1151,
     "status": "error",
     "timestamp": 1603005668271,
     "user": {
      "displayName": "Python Simplified",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh-cjP-_1ESwkpGiDhXCJp3kOwzBN0UNevCALxWhg=s64",
      "userId": "05471425677068167747"
     },
     "user_tz": 420
    },
    "id": "UarVOe0WTYEq",
    "outputId": "b20c9f5f-cb75-4c12-ceb4-4460b29ddab0"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bcb5f10bf957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcheckpoint_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Lessons/storyTeller/checkpoint5.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mindex_to_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bcb5f10bf957>\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'StoryTeller' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.optimizer_state = checkpoint['optimizer_state']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.device = checkpoint['device']\n",
    "    model.word_to_index = checkpoint['word_to_idxx']\n",
    "    model.index_to_word = checkpoint['idx_to_word']\n",
    "    model.average_loss = checkpoint['average_loss']\n",
    "    return model\n",
    "\n",
    "checkpoint_url = '/content/drive/My Drive/Lessons/storyTeller/checkpoint5.pth'\n",
    "model = load_checkpoint(checkpoint_url)\n",
    "index_to_word = model.index_to_word\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXnfIAhyNNn1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loss_plot = pd.DataFrame(model.average_loss)\n",
    "loss_plot.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgJKcqqCUp6I"
   },
   "source": [
    "# **Predict Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ess7PHw-UswI"
   },
   "outputs": [],
   "source": [
    "def predict(model, first_words ,story_len ,top_k):\n",
    "    '''\n",
    "    param model: trained model\n",
    "    param first_words: a string of 5 (n_feature) words to begin the story\n",
    "    param story_len: an integer symbolizing the number of words you'd like the story to have\n",
    "    param top_k: the number of top probabilities per word that the network will randomly select from\n",
    "    '''\n",
    "    feature = (first_words.lower()).split(\" \")\n",
    "    for i in feature:\n",
    "        story.append(i)\n",
    "    for i in range(story_len):\n",
    "        feature_idx = torch.tensor([word_to_index[word] for word in feature], dtype=torch.long)\n",
    "        feature_idx = feature_idx.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model.double().forward(feature_idx)\n",
    "        ps = torch.exp(output)\n",
    "        topk_combined = ps.topk(top_k, sorted=True)\n",
    "        #top kk probabilities\n",
    "        topk_ps = topk_combined[0][0]\n",
    "        #top kk classes\n",
    "        topk_class = topk_combined[1][0]\n",
    "        topk_class = [index_to_word[int(i)] for i in topk_class]\n",
    "        next_word = random.choice(topk_class)\n",
    "        feature = feature[1:]\n",
    "        feature.append(next_word)\n",
    "        story.append(next_word)\n",
    "    return story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dg6KWKpeU0GB"
   },
   "source": [
    "# **Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLdMEMOqU2rn"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "first_words = input('Type the first {} words to start the story:\\nexample: A lovely day at the\\n'.format(batch_size))\n",
    "\n",
    "top_k = 3\n",
    "story_len = 50\n",
    "story = []\n",
    "device = 'cuda:0'\n",
    "\n",
    "#Predicting and Handling User-Input Errors\n",
    "try:      \n",
    "    prediction = predict(model, first_words, story_len, top_k)\n",
    "except KeyError as error:\n",
    "    print('Oops, looks like you\\'ve selected a word that the network does not understand yet: ', error)\n",
    "    if story[0] != \"\":\n",
    "        story = story[len(first_words):]\n",
    "    first_words = input('please select a different word:\\nexample: A lovely day at the\\n')\n",
    "    prediction = predict(model, first_words, story_len, top_k)\n",
    "except KeyError and RuntimeError:\n",
    "    if story[0] != \"\":\n",
    "        story = story[len(first_words):]\n",
    "    first_words = input('Oops, looks like you\\'ve typed {} words instead of {}!\\n\\nType the first 5 words to start the story:\\nexample: A lovely day at the\\n'.format(len(first_words.split(\" \")), n_features))\n",
    "    prediction = predict(model, first_words, story_len, top_k)\n",
    "\n",
    "print('-----------------------------------------------------\\n The STORY \\n-----------------------------------------------------')\n",
    "print(\" \".join(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIKJrOv8dkRn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONT80H1b3/ZZ3/X+DHE5gF",
   "collapsed_sections": [],
   "name": "storyTeller2noValidation_demoFile.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
