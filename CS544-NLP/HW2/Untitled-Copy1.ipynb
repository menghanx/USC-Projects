{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5f7a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\xmh91\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import nltk\n",
    "import time\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload After restart\n",
    "w2v_google_model = api.load('word2vec-google-news-300')\n",
    "model = Word2Vec.load(\"tained_word2vec.model\")\n",
    "#model = Word2Vec.load(\"tained_word2vec_random1.model\")\n",
    "w2v_review_model = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a08fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload After restart\n",
    "### Raw review data in df\n",
    "df = pd.read_csv(\"250k_classified_reviews.csv\", sep='\\t')\n",
    "\n",
    "# Calculate Accuracy\n",
    "def getAccuracy(out, labels):\n",
    "    _, predict = torch.max(out.data, 1)\n",
    "    total = labels.shape[0]*1.0\n",
    "    correct = (labels == predict).sum().item()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b393f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ccfdbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n",
      "weight_ih_l0 torch.Size([20, 10])\n",
      "weight_hh_l0 torch.Size([20, 20])\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 torch.Size([20])\n",
      "weight_ih_l1 torch.Size([20, 20])\n",
      "weight_hh_l1 torch.Size([20, 20])\n",
      "bias_ih_l1 torch.Size([20])\n",
      "bias_hh_l1 torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# input_size = 10, hidden_size = 20, num_layers = 2\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "inputs = torch.randn(5, 3, 10)  # (time_step, batch_size, input_size)\n",
    "h0 = torch.randn(2, 3, 20)  # (num_layers, batch_size, hidden_size)\n",
    "output, hn = rnn(inputs, h0)\n",
    "print(output.shape)  # (time_step, batch_size, hidden_size)\n",
    "\n",
    "for name, param in rnn.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab024875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(2019)\n",
    "\n",
    "# 超参设置\n",
    "TIME_STEP = 10  # RNN时间步长\n",
    "INPUT_SIZE = 1  # RNN输入尺寸\n",
    "INIT_LR = 0.02  # 初始学习率\n",
    "N_EPOCHS = 100  # 训练回数\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=32,  # RNN隐藏神经元个数\n",
    "            num_layers=1,  # RNN隐藏层个数\n",
    "        )\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        # x (time_step, batch_size, input_size)\n",
    "        # h (n_layers, batch, hidden_size)\n",
    "        # out (time_step, batch_size, hidden_size)\n",
    "        out, h = self.rnn(x, h)\n",
    "        prediction = self.out(out)\n",
    "        return prediction, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ad5494b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2844/3934371778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=300,\n",
    "            hidden_size=50,  # RNN隐藏神经元个数\n",
    "            num_layers=1,  # RNN隐藏层个数\n",
    "            batch_first=True\n",
    "        )\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(50, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    # inputs = (time_step, batch_size, input_size)\n",
    "    def forward(self,inputs,hidden):\n",
    "        output,hidden = self.rnn(inputs,hidden)\n",
    "        # select last output\n",
    "        output = output[:,-1,:]\n",
    "        output = self.out(output)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 50, 50)  \n",
    "    \n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.005)\n",
    "loss_func = nn.MSELoss()\n",
    "h_state = None\n",
    "\n",
    "\n",
    "\n",
    "h0 = rnn.initHidden()\n",
    "output, hn = rnn(test_input, h0)\n",
    "print(output) # (time_step, batch_size, hidden_size)\n",
    "\n",
    "getAccuracy(output, test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce00c3",
   "metadata": {},
   "source": [
    "Num of Reviews = Batch\n",
    "Num of words = Sequence\n",
    "input_size = 300\n",
    "hidden_size = 50\n",
    "output_size = 3 or 2 accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2515010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b899b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ec733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbd04d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
