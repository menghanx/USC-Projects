{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5f7a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\xmh91\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import nltk\n",
    "import time\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b173530",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload After restart\n",
    "#w2v_google_model = api.load('word2vec-google-news-300')\n",
    "model = Word2Vec.load(\"tained_word2vec.model\")\n",
    "#model = Word2Vec.load(\"tained_word2vec_random1.model\")\n",
    "w2v_review_model = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76b13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload After restart\n",
    "### Raw review data in df\n",
    "df = pd.read_csv(\"250k_classified_reviews.csv\", sep='\\t')\n",
    "\n",
    "# Calculate Accuracy\n",
    "def getAccuracy(out, labels):\n",
    "    _, predict = torch.max(out.data, 1)\n",
    "    total = labels.shape[0]*1.0\n",
    "    correct = (labels == predict).sum().item()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0e8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 50 vec for each review\n",
    "def paddedVec(w2v_model, train_input):\n",
    "    res = []\n",
    "\n",
    "    for review in train_input:\n",
    "        docVec = []\n",
    "        words = review.split()\n",
    "        if len(words) >= 50 :\n",
    "            words = words[:50]     \n",
    "        else:\n",
    "            #words = [\"0\" for _ in range(50 - len(words))] + words\n",
    "            docVec = [np.zeros(300,) for _ in range(50 - len(words))]\n",
    "        \n",
    "        for word in words:\n",
    "            if word in w2v_model:\n",
    "                docVec.append(w2v_model[word])\n",
    "            else:\n",
    "                docVec.append(np.zeros(300,))\n",
    "        \n",
    "        res.append(docVec)\n",
    "\n",
    "    return np.array(res, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "165c4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "    \n",
    "class SeqRNN(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,hidden_size,output_size):\n",
    "        super(SeqRNN,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn = nn.RNN(self.vocab_size,self.hidden_size,batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size,self.output_size)\n",
    "        \n",
    "    def forward(self,input): \n",
    "        batch_size = len(input)\n",
    "        h0 = torch.zeros(1,batch_size,self.hidden_size).to(device)\n",
    "        output , hidden = self.rnn(input,h0)\n",
    "        output = output[ : ,-1, : ]\n",
    "        output = self.linear(output)\n",
    "        output = torch.nn.functional.softmax(output,dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bf6b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "###### For for each loop ######\n",
    "# Use Model to compute accracy from test_set and test_labels\n",
    "def test_accuracy(model, test_set, test_labels):\n",
    "    total = len(test_set)\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(total):\n",
    "        review = test_set[i]\n",
    "        pred = predict_review(review, model)\n",
    "        if pred == test_labels[i]:\n",
    "            correct += 1\n",
    "    return correct * 1.0 / total\n",
    "\n",
    "# Ouput the predicted sentiment of a sentence\n",
    "def predict_review(review, model):\n",
    "    input_tensor = torch.tensor([review]).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(input_tensor)\n",
    "        out = torch.argmax(out).item()\n",
    "    # Delete tensor from GPU\n",
    "    del input_tensor\n",
    "    return out\n",
    "\n",
    "\n",
    "###### For dataloader enumerate loop ######\n",
    "\n",
    "def test_accuracy_loader(model, test_loader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for _, (review, label) in enumerate(test_loader):\n",
    "        total += len(label)\n",
    "        pred = predict_review_tensor(review, model)\n",
    "        correct += (pred == label).sum()\n",
    "    return correct.item() * 1.0 / total\n",
    "\n",
    "def predict_review_tensor(review, model):\n",
    "    with torch.no_grad():\n",
    "        out = model(review)\n",
    "        out = torch.argmax(out).item()\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba9ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep only class 1 and 2 for Binary Classification\n",
    "df_sm = pd.concat([df[df['class'] == 1], df[df['class'] == 2]])\n",
    "## Drop Null reviews\n",
    "df_sm = df_sm.dropna(subset=['review'])\n",
    "\n",
    "# Sample less data due to memory constraint\n",
    "df_sm = df_sm.sample(2000)\n",
    "\n",
    "\n",
    "# Split train and test data\n",
    "reviews = df_sm[\"review\"]\n",
    "labels = df_sm[\"class\"]\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(reviews, labels, test_size = 0.2)\n",
    "\n",
    "## Turn Train and Test set and labels to numpy array\n",
    "train_set = paddedVec(w2v_review_model, train_set)\n",
    "test_set = paddedVec(w2v_review_model, test_set)\n",
    "\n",
    "## Substract 1 from labels, so the classes starts from 0\n",
    "train_labels = train_labels.to_numpy() - 1\n",
    "test_labels = test_labels.to_numpy() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40befb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "## Data Loader\n",
    "\n",
    "## Keep only class 1 and 2 for Binary Classification\n",
    "df_sm = pd.concat([df[df['class'] == 1], df[df['class'] == 2]])\n",
    "## Drop Null reviews\n",
    "df_sm = df_sm.dropna(subset=['review'])\n",
    "\n",
    "# Sample less data due to memory constraint\n",
    "df_sm = df_sm.sample(2000)\n",
    "\n",
    "\n",
    "# Split train and test data\n",
    "reviews = df_sm[\"review\"]\n",
    "labels = df_sm[\"class\"]\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(reviews, labels, test_size = 0.2)\n",
    "\n",
    "## Turn Train and Test set and labels to numpy array\n",
    "train_set = paddedVec(w2v_review_model, train_set)\n",
    "test_set = paddedVec(w2v_review_model, test_set)\n",
    "\n",
    "## Substract 1 from labels, so the classes starts from 0\n",
    "train_labels = train_labels.to_numpy() - 1\n",
    "test_labels = test_labels.to_numpy() - 1\n",
    "\n",
    "## Train & test tensors\n",
    "train_set = torch.from_numpy(train_set).float().to(device)\n",
    "test_set = torch.from_numpy(test_set).float().to(device)\n",
    "train_labels = torch.from_numpy(train_labels).type(torch.LongTensor).to(device)\n",
    "test_labels = torch.from_numpy(test_labels).type(torch.LongTensor).to(device)\n",
    "\n",
    "\n",
    "## Prepare TensorDataset and DataLoader\n",
    "training_set = TensorDataset(train_set, train_labels)\n",
    "testing_set = TensorDataset(test_set, test_labels)\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(testing_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511631bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (batch_idx, (reviews, labels)) in enumerate(train_loader):\n",
    "    print(\"\")\n",
    "    print(reviews.size())\n",
    "    print(len(labels))\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6a45b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Timetaken: 3.60s train_loss: 0.3771 accuracy: 0.6225\n",
      "Epoch: 1 Timetaken: 3.57s train_loss: 0.3356 accuracy: 0.6750\n"
     ]
    }
   ],
   "source": [
    "model = SeqRNN(300,50,2)\n",
    "model.to(device)\n",
    "epoches = 2\n",
    "every_epoch = 1\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0003)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(epoches):\n",
    "    # Train all sentences from train set\n",
    "    for i, (review, label) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(review)\n",
    "        loss = loss_func(pred,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if e % every_epoch == 0:\n",
    "        accuracy = test_accuracy_loader(model, test_loader)\n",
    "        timetaken = time.time() - start_time\n",
    "        print(\"Epoch: {} Timetaken: {:.2f}s train_loss: {:.4f} accuracy: {:.4f}\".format(e, timetaken, loss, accuracy))\n",
    "        start_time = time.time()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7f3266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Timetaken: 70.93s train_loss: 0.3152 accuracy: 0.7368\n",
      "Epoch: 1 Timetaken: 70.89s train_loss: 0.3162 accuracy: 0.7260\n",
      "Epoch: 2 Timetaken: 73.01s train_loss: 0.3161 accuracy: 0.7352\n"
     ]
    }
   ],
   "source": [
    "model = SeqRNN(300,50,2)\n",
    "model.to(device)\n",
    "epoches = 3\n",
    "every_epoch = 1\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0003)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(epoches):\n",
    "    # Train all sentences from train set\n",
    "    for i in range(len(train_set)):\n",
    "        #index = random.randint(0, len(train_labels)-1)\n",
    "        review = train_set[i]\n",
    "        label = train_labels[i]\n",
    "        input_tensor = torch.tensor([review]).float().to(device)\n",
    "        label_tensor = torch.tensor([label]).type(torch.LongTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(input_tensor)\n",
    "        loss = loss_func(pred,label_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        del input_tensor\n",
    "        del label_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "    # Report accuracy on test set every_epoch\n",
    "    if e % every_epoch == 0:\n",
    "        accuracy = test_accuracy(model, test_set, test_labels)\n",
    "        timetaken = time.time() - start_time\n",
    "        print(\"Epoch: {} Timetaken: {:.2f}s train_loss: {:.4f} accuracy: {:.4f}\".format(e, timetaken, loss, accuracy))\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729deb0",
   "metadata": {},
   "source": [
    "Cuda - For Loop\n",
    "Epoch: 0 Timetaken: 53.23s train_loss: 0.3510 accuracy: 0.7465\n",
    "Epoch: 1 Timetaken: 56.13s train_loss: 0.3261 accuracy: 0.7432\n",
    "Epoch: 2 Timetaken: 53.85s train_loss: 0.3234 accuracy: 0.7458\n",
    "Epoch: 3 Timetaken: 52.89s train_loss: 0.3162 accuracy: 0.7415\n",
    "Epoch: 4 Timetaken: 52.95s train_loss: 0.3143 accuracy: 0.7532\n",
    "Epoch: 5 Timetaken: 52.50s train_loss: 0.3139 accuracy: 0.7635\n",
    "Epoch: 6 Timetaken: 52.86s train_loss: 0.3139 accuracy: 0.7620\n",
    "Epoch: 7 Timetaken: 53.07s train_loss: 0.3138 accuracy: 0.7575\n",
    "Epoch: 8 Timetaken: 57.89s train_loss: 0.3134 accuracy: 0.7692\n",
    "Epoch: 9 Timetaken: 53.21s train_loss: 0.3161 accuracy: 0.7668"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d445cc",
   "metadata": {},
   "source": [
    "CPU - For Loop\n",
    "Epoch: 0 Timetaken: 70.93s train_loss: 0.3152 accuracy: 0.7368\n",
    "Epoch: 1 Timetaken: 70.89s train_loss: 0.3162 accuracy: 0.7260\n",
    "Epoch: 2 Timetaken: 73.01s train_loss: 0.3161 accuracy: 0.7352"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e1811",
   "metadata": {},
   "source": [
    "Num of Reviews = Batch\n",
    "Num of words = Sequence\n",
    "input_size = 300\n",
    "hidden_size = 50\n",
    "output_size = 3 or 2 accordingly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
