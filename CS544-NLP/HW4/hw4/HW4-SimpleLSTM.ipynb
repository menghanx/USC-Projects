{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16df99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, re, json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.datasets as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5472c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train sentences \n",
    "train_file = 'data/train'\n",
    "dev_file = 'data/dev'\n",
    "test_file = 'data/test'\n",
    "dummy_file ='data/dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a694668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train/test file, each line as {s_idx, word, tag} tuple, store in a list\n",
    "def readFile(file):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            words.append(line.strip().split(' '))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c9b2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EU</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>German</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s_idx     word     tag\n",
       "0     1       EU   B-ORG\n",
       "1     2  rejects       O\n",
       "2     3   German  B-MISC\n",
       "3     4     call       O\n",
       "4     5       to       O"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF: index - s_idx - word - tag\n",
    "train_lines = readFile(train_file)\n",
    "df = pd.DataFrame(train_lines, columns = [\"s_idx\", \"word\", \"tag\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21720b11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab words: 11983\n",
      "rare words: 11641\n"
     ]
    }
   ],
   "source": [
    "# Randomly select some rare words to be <unk> words\n",
    "unique_words = df[\"word\"].value_counts().reset_index()\n",
    "unique_words.columns = [\"word\", \"freq\"]\n",
    "threshold = 1\n",
    "# words with freq > 1\n",
    "vocab_words = unique_words[ unique_words['freq'] > threshold ]\n",
    "# words with freq = 1\n",
    "rare_words = unique_words[ unique_words['freq'] == threshold ]\n",
    "\n",
    "print(\"vocab words:\", vocab_words.shape[0])\n",
    "print(\"rare words:\", rare_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6455658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 3000 words from rare words to set as unknown words\n",
    "unk_count = 3000\n",
    "unk_words = rare_words.sample(unk_count)\n",
    "\n",
    "# drop the selected rare words from vocab\n",
    "rare_words = rare_words.drop(unk_words.index)\n",
    "\n",
    "# build new vocab = freq_words + rest_rare_words + <unk>\n",
    "vocab_words = vocab_words.append(rare_words, ignore_index=True)\n",
    "\n",
    "# custom words unk, pad etc\n",
    "custom_vocab = ['<unk>']\n",
    "\n",
    "# main vocab list, to generate embedding\n",
    "vocab_set = set(custom_vocab + vocab_words['word'].unique().tolist())\n",
    "vocab_size = len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2493caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the vocab\n",
    "word_to_idx = {word:i for i, word in enumerate(vocab_set)}\n",
    "\n",
    "# all the unique tags\n",
    "unique_tags = set(df[\"tag\"].unique())\n",
    "tag_to_idx = {tag:i for i, tag in enumerate(unique_tags)}\n",
    "idx_to_tag = {i:tag for i, tag in enumerate(unique_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbac17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files, group words by sentence, return list of sentences\n",
    "def readData(file):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            sentences.append(sentence.copy())\n",
    "            sentence.clear()\n",
    "        else:\n",
    "            sentence.append(line.strip().split(' '))\n",
    "    # append the last sentence\n",
    "    sentences.append(sentence.copy())\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88d8db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word = [idx, word, tag]  train_data = list of sentences in term of list of words\n",
    "train_data = readData(train_file)\n",
    "\n",
    "dev_data = readData(dev_file)\n",
    "# word = [idx, word]\n",
    "test_data = readData(test_file)\n",
    "\n",
    "# Dummy test data\n",
    "dummy_file ='data/dummy'\n",
    "dummy_data = readData(dummy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "53122e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14987 3466 3684\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences), len(dev_sentences), len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "456f27a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['1', 'Weaver', 'B-PER'],\n",
       "  ['2', 'shot', 'O'],\n",
       "  ['3', 'to', 'O'],\n",
       "  ['4', 'prominence', 'O'],\n",
       "  ['5', 'in', 'O'],\n",
       "  ['6', '1994', 'O'],\n",
       "  ['7', 'when', 'O'],\n",
       "  ['8', 'he', 'O'],\n",
       "  ['9', 'won', 'O'],\n",
       "  ['10', 'the', 'O'],\n",
       "  ['11', 'English', 'B-MISC'],\n",
       "  ['12', '2,000', 'B-MISC'],\n",
       "  ['13', 'Guineas', 'I-MISC'],\n",
       "  ['14', 'on', 'O'],\n",
       "  ['15', 'Mister', 'B-LOC'],\n",
       "  ['16', 'Baileys', 'I-LOC'],\n",
       "  ['17', 'in', 'O'],\n",
       "  ['18', 'his', 'O'],\n",
       "  ['19', 'first', 'O'],\n",
       "  ['20', 'ride', 'O'],\n",
       "  ['21', 'in', 'O'],\n",
       "  ['22', 'a', 'O'],\n",
       "  ['23', 'classic', 'O'],\n",
       "  ['24', '.', 'O']],\n",
       " [['1', 'Results', 'O'],\n",
       "  ['2', 'of', 'O'],\n",
       "  ['3', 'English', 'B-MISC'],\n",
       "  ['4', 'league', 'O'],\n",
       "  ['5', 'matches', 'O']]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3f339e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preapare training data\n",
    "def processData(tuples):\n",
    "    training_data = []\n",
    "    for t in tuples:\n",
    "        training_data.append( ( [ word[1] if word[1] in word_to_idx else '<unk>' for word in t ], [ word[2] for word in t ] ) )\n",
    "    return training_data\n",
    "\n",
    "# Convert sequence into tensor\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0bbd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = processData(dummy_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2ff5a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Weaver', 'shot', 'to', 'prominence', 'in', '1994', 'when', 'he', 'won', 'the', 'English', '2,000', 'Guineas', 'on', 'Mister', 'Baileys', 'in', 'his', 'first', 'ride', 'in', 'a', '<unk>', '.']\n",
      "['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'B-MISC', 'I-MISC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "['Results', 'of', 'English', 'league', 'matches']\n",
      "['O', 'O', 'B-MISC', 'O', 'O']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for sent, t in training_data:\n",
    "    print(sent)\n",
    "    print(t)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef93632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "vocab_size = len(word_to_idx)\n",
    "tagset_size = len(tag_to_idx)\n",
    "\n",
    "lstm_layer = 1\n",
    "lstm_dropout = 0.33\n",
    "linear_out_dim = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e298e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "    \n",
    "    # sentence [seq, batch, embed_dim]\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "13ebac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb5b1b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-LOC', 'I-ORG', 'B-MISC', 'B-MISC', 'B-MISC']\n",
      "tensor(2.1384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0834, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "['O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Before training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_idx)\n",
    "    tag_scores = model(inputs)\n",
    "    print([idx_to_tag[i] for i in torch.argmax(tag_scores, dim=1).tolist()])\n",
    "\n",
    "print_every = 30\n",
    "    \n",
    "for epoch in range(300):\n",
    "    for sentence, tags in training_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        sentence_in = prepare_sequence(sentence, word_to_idx)\n",
    "        targets = prepare_sequence(tags, tag_to_idx)\n",
    "        \n",
    "        tag_scores = model(sentence_in)\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%print_every == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    \n",
    "# After training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_idx)\n",
    "    tag_scores = model(inputs)\n",
    "    print([idx_to_tag[i] for i in torch.argmax(tag_scores, dim=1).tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c0f8e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'B-MISC', 'I-MISC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_idx)\n",
    "    tag_scores = model(inputs)\n",
    "    print([idx_to_tag[i] for i in torch.argmax(tag_scores, dim=1).tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18defae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-MISC',\n",
       " 'B-MISC',\n",
       " 'I-MISC',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "2b0cb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, linear_out_dim, lstm_layer, lstm_dropout):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.num_layers = lstm_layer\n",
    "        self.out_size = num_classes\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        # Linear 1\n",
    "        self.fc1 = nn.Linear(2*self.hidden_size,linear_out_dim)\n",
    "        # classifier linear\n",
    "        self.fc2 = nn.Linear(linear_out_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(lstm_dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "#         h0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "#         c0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "        h0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "        # embedding layer + dropout\n",
    "        x = self.dropout(self.embedding(x))\n",
    "        # BLSTM layer\n",
    "        x , _ = self.bilstm(x)\n",
    "        # Linear + ELU\n",
    "        x = F.elu(self.fc1(x))\n",
    "        # classifier\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x.view(seq_len, self.out_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "fff942e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1715,  0.3064, -0.1101,  0.5220, -0.4690, -0.6432, -0.3959, -0.0424,\n",
      "          1.0491, -0.0986],\n",
      "        [ 0.9205,  0.5053, -0.2874, -0.0737, -0.8828, -0.5819,  0.3481,  1.1651,\n",
      "          0.3174,  0.9363]])\n",
      "tensor([[-0.3601, -1.0359,  0.1784,  0.9853,  0.2091],\n",
      "        [ 0.0415, -0.8341,  0.7340,  0.5089, -0.0962]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1133, 0.0576, 0.1941, 0.4349, 0.2001],\n",
       "        [0.1700, 0.0708, 0.3398, 0.2713, 0.1481]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input = torch.randn(2,10)\n",
    "out = F.elu(input)\n",
    "print(out)\n",
    "fc = nn.Linear(10,5)\n",
    "out = fc(out)\n",
    "print(out)\n",
    "F.augmaF.softmax(out, dim=1)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc92f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:42<00:00, 353.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 344.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:41<00:00, 357.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:47<00:00, 315.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 344.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 341.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:44<00:00, 335.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:41<00:00, 361.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:41<00:00, 360.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 346.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 344.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:41<00:00, 363.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 347.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 343.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:42<00:00, 355.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:43<00:00, 344.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:42<00:00, 353.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:42<00:00, 355.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:42<00:00, 356.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:42<00:00, 349.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 13662/14987 [00:38<00:03, 360.10it/s]"
     ]
    }
   ],
   "source": [
    "blstm_model = BLSTM(len(vocab_set),embedding_dim, hidden_dim, num_classes, linear_out_dim, lstm_layer, lstm_dropout).to(device)\n",
    "optimizer = torch.optim.SGD(blstm_model.parameters(), lr=0.1)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "epochs = 50\n",
    "\n",
    "input_batch, target_batch = makeData(train_sentences)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train one sentence at a time\n",
    "    for input, target in tqdm(zip(input_batch, target_batch), total=len(input_batch)):\n",
    "\n",
    "        x = torch.LongTensor([input]).to(device)\n",
    "        y = torch.LongTensor(target).to(device)\n",
    "        preds = blstm_model(x)\n",
    "        loss = loss_func(preds,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3399e97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLSTM(\n",
       "  (embedding): Embedding(20625, 100)\n",
       "  (bilstm): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       "  (dropout): Dropout(p=0.33, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm_model = BLSTM(len(vocab_set),embedding_dim, hidden_dim, num_classes, linear_out_dim, lstm_layer, lstm_dropout).to(device)\n",
    "blstm_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
