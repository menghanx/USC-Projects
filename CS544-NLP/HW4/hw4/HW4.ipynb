{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860142f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, re, json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.datasets as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e48439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            words.append(line.strip().split(' '))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39679e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train sentences \n",
    "train_file = 'data/train'\n",
    "dev_file = 'data/dev'\n",
    "test_file = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d147ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = readFile(train_file)\n",
    "df = pd.DataFrame(train_lines, columns = [\"s_idx\", \"word\", \"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f146f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab words: 11983\n",
      "rare words: 11641\n"
     ]
    }
   ],
   "source": [
    "# Randomly select some rare words to be <unk> words\n",
    "unique_words = df[\"word\"].value_counts().reset_index()\n",
    "unique_words.columns = [\"word\", \"freq\"]\n",
    "threshold = 1\n",
    "vocab_words = unique_words[ unique_words['freq'] > threshold ]\n",
    "rare_words = unique_words[ unique_words['freq'] == threshold ]\n",
    "print(\"vocab words:\", vocab_words.shape[0])\n",
    "print(\"rare words:\", rare_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2869dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 3000 words from rare words to set as unknown words\n",
    "unk_count = 3000\n",
    "unk_rares = rare_words.sample(unk_count)\n",
    "\n",
    "# Use this list to replace train words to <unk>\n",
    "unk_set = set(unk_rares[\"word\"].unique().tolist())\n",
    "\n",
    "# drop selected rare words from rare words\n",
    "rest_rares = rare_words.drop(unk_rares.index)\n",
    "\n",
    "# build new vocab = freq_words + rest_rare_words + <unk>\n",
    "vocab = vocab_words.append(rest_rares, ignore_index=True)\n",
    "unk_row = pd.DataFrame([[\"<unk>\", 3000]], columns = [\"word\", \"freq\"])\n",
    "vocab = vocab.append(unk_row, ignore_index=True)\n",
    "\n",
    "# main vocab list, to generate embedding\n",
    "vocab_set = set(vocab['word'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22aca2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the vocab\n",
    "word_to_idx = {word:i for i, word in enumerate(vocab_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3a62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSentences(file):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            sentences.append(sentence.copy())\n",
    "            sentence.clear()\n",
    "        else:\n",
    "            sentence.append(line.strip().split(' '))\n",
    "    # append the last sentence\n",
    "    sentences.append(sentence.copy())\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d6a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sentences together\n",
    "train_file = 'data/train'\n",
    "dev_file = 'data/dev'\n",
    "test_file = 'data/test'\n",
    "\n",
    "# word = [idx, word, tag]\n",
    "train_sentences = readSentences(train_file)\n",
    "dev_sentences = readSentences(dev_file)\n",
    "# word = [idx, word]\n",
    "test_sentences = readSentences(test_file)\n",
    "\n",
    "# Dummy test data\n",
    "dummy_file ='data/dummy'\n",
    "dummy_sentences = readSentences(dummy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a456c981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14987 3466 3684\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences), len(dev_sentences), len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e91450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def makeData(sentences):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for sentence in sentences:\n",
    "        word_idx = []\n",
    "        target = []\n",
    "        for word in sentence:\n",
    "            if word[1] in vocab_set:\n",
    "                word_idx.append(word_to_idx[word[1]])\n",
    "            else:\n",
    "                word_idx.append(word_to_idx['<unk>'])            \n",
    "            target.append(tag_to_idx[word[2]])\n",
    "        inputs.append(word_idx)\n",
    "        targets.append(target)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7031dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take sentences array, return embedding index, and targets\n",
    "# def makeData(sentences):\n",
    "#     # List of list of tensor idx, each idx represent a word in the sentence\n",
    "#     inputs = []\n",
    "#     # list of list of int idx, each idx represent a tag.\n",
    "#     targets = []\n",
    "#     for sentence in sentences:\n",
    "#         word_idx = []\n",
    "#         target = []\n",
    "#         for word in sentence:\n",
    "#             if word[1] in vocab_set:\n",
    "#                 # convert int index to torch.long\n",
    "#                 word_idx.append(torch.tensor(word_to_idx[word[1]], dtype=torch.long))\n",
    "#             else:\n",
    "#                 word_idx.append(torch.tensor(word_to_idx['<unk>'], dtype=torch.long))            \n",
    "#             target.append(tag_to_idx[word[2]])\n",
    "#         inputs.append(word_idx)\n",
    "#         targets.append(target)\n",
    "#     return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f478f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the unique tags\n",
    "tags = set(df[\"tag\"].unique())\n",
    "tag_to_idx = {tag:i for i, tag in enumerate(tags)}\n",
    "num_classes = len(df[\"tag\"].unique())\n",
    "\n",
    "embedding_dim = 100\n",
    "lstm_layer = 1\n",
    "hidden_dim = 256\n",
    "lstm_dropout = 0.33\n",
    "linear_out_dim = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc052788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, linear_out_dim, lstm_layer, lstm_dropout):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.num_layers = lstm_layer\n",
    "        self.out_size = num_classes\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        # Linear 1\n",
    "        self.fc1 = nn.Linear(2*self.hidden_size,linear_out_dim)\n",
    "        # classifier linear\n",
    "        self.fc2 = nn.Linear(linear_out_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(lstm_dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "#         h0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "#         c0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "        h0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.randn(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "        # embedding layer + dropout\n",
    "        x = self.dropout(self.embedding(x))\n",
    "        # BLSTM layer\n",
    "        x , _ = self.bilstm(x)\n",
    "        # Linear + ELU\n",
    "        x = F.elu(self.fc1(x))\n",
    "        # classifier\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x.view(seq_len, self.out_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "54482e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1715,  0.3064, -0.1101,  0.5220, -0.4690, -0.6432, -0.3959, -0.0424,\n",
      "          1.0491, -0.0986],\n",
      "        [ 0.9205,  0.5053, -0.2874, -0.0737, -0.8828, -0.5819,  0.3481,  1.1651,\n",
      "          0.3174,  0.9363]])\n",
      "tensor([[-0.3601, -1.0359,  0.1784,  0.9853,  0.2091],\n",
      "        [ 0.0415, -0.8341,  0.7340,  0.5089, -0.0962]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1133, 0.0576, 0.1941, 0.4349, 0.2001],\n",
       "        [0.1700, 0.0708, 0.3398, 0.2713, 0.1481]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input = torch.randn(2,10)\n",
    "out = F.elu(input)\n",
    "print(out)\n",
    "fc = nn.Linear(10,5)\n",
    "out = fc(out)\n",
    "print(out)\n",
    "F.augmaF.softmax(out, dim=1)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d44571e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1001/14987 [00:02<00:40, 344.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21840/3591734674.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py39-CS544\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21840/2672824358.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# BLSTM layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbilstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;31m# Linear + ELU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py39-CS544\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py39-CS544\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    681\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "blstm_model = BLSTM(len(vocab_set),embedding_dim, hidden_dim, num_classes, linear_out_dim, lstm_layer, lstm_dropout).to(device)\n",
    "optimizer = torch.optim.SGD(blstm_model.parameters(), lr=0.1)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "epochs = 1\n",
    "\n",
    "input_batch, target_batch = makeData(train_sentences)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train one sentence at a time\n",
    "    for input, target in tqdm(zip(input_batch, target_batch), total=len(input_batch)):\n",
    "\n",
    "        x = torch.LongTensor([input]).to(device)\n",
    "        y = torch.LongTensor(target).to(device)\n",
    "        preds = blstm_model(x)\n",
    "        loss = loss_func(preds,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "0464f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLSTM(\n",
       "  (embedding): Embedding(20625, 100)\n",
       "  (bilstm): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       "  (dropout): Dropout(p=0.33, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm_model = BLSTM(len(vocab_set),embedding_dim, hidden_dim, num_classes, linear_out_dim, lstm_layer, lstm_dropout).to(device)\n",
    "blstm_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
