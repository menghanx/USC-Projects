{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16df99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, re, json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch as t\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.datasets as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a6c5930e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 113, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# TEST\n",
    "# variable length sorted\n",
    "a = [torch.randn(113,100), torch.randn(3,100), torch.randn(2,100), torch.randn(1,100)]\n",
    "seq = [113,3,2,1]\n",
    "b = pad_sequence(a, batch_first=True, padding_value=0) # b.shape (4, 113, 100)\n",
    "print(b.shape)\n",
    "c = pack_padded_sequence(b, seq, batch_first=True) # c.data.shape (11, 12)\n",
    "c\n",
    "\n",
    "\n",
    "type(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08586db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = nn.LSTM(input_size = 12, hidden_size = 16, batch_first = True, bidirectional = False, num_layers = 1)\n",
    "b_result, hidden = lstm_layer(b)\n",
    "print(b_result.shape) # b_result.shape (4, 5, 16)\n",
    "c_result, hidden = lstm_layer(c)\n",
    "print(c_result.data.shape) # c_result.data.shape (11, 16)\n",
    "\n",
    "\n",
    "lstm_layer = nn.LSTM(input_size = 12, hidden_size = 16, batch_first = True, bidirectional = True, num_layers = 1)\n",
    "\n",
    "b_result, hidden = lstm_layer(b)\n",
    "print(b_result.shape) # b_result.shape (4, 5, 32)\n",
    "\n",
    "c_result, hidden = lstm_layer(c)\n",
    "print(c_result.data.shape) # c_result.data.shape (11, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab5472c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train sentences \n",
    "train_file = 'data/train'\n",
    "dev_file = 'data/dev'\n",
    "test_file = 'data/test'\n",
    "dummy_file ='data/dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a694668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train/test file, each line as {s_idx, word, tag} tuple, store in a list\n",
    "def readFile(file):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            words.append(line.strip().split(' '))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3c9b2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EU</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>German</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s_idx     word     tag\n",
       "0     1       EU   B-ORG\n",
       "1     2  rejects       O\n",
       "2     3   German  B-MISC\n",
       "3     4     call       O\n",
       "4     5       to       O"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF: index - s_idx - word - tag\n",
    "train_lines = readFile(train_file)\n",
    "df = pd.DataFrame(train_lines, columns = [\"s_idx\", \"word\", \"tag\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21720b11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab words: 6182\n",
      "rare words: 17442\n"
     ]
    }
   ],
   "source": [
    "# Randomly select some rare words to be <unk> words\n",
    "unique_words = df[\"word\"].value_counts().reset_index()\n",
    "unique_words.columns = [\"word\", \"freq\"]\n",
    "threshold = 3\n",
    "# words with freq > threshold\n",
    "vocab_words = unique_words[ unique_words['freq'] > threshold ]\n",
    "# words with freq <= threshold\n",
    "rare_words = unique_words[ unique_words['freq'] <= threshold ]\n",
    "\n",
    "print(\"vocab words:\", vocab_words.shape[0])\n",
    "print(\"rare words:\", rare_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6455658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 3000 words from rare words to set as unknown words\n",
    "# unk_count = len(rare_words)\n",
    "# unk_words = rare_words.sample(unk_count)\n",
    "\n",
    "# drop the selected rare words from vocab\n",
    "# rare_words = rare_words.drop(unk_words.index)\n",
    "\n",
    "# build new vocab = freq_words + rest_rare_words + <unk>\n",
    "# vocab_words = vocab_words.append(rare_words, ignore_index=True)\n",
    "\n",
    "# custom words unk, pad etc\n",
    "# custom_vocab = ['<unk>']\n",
    "custom_vocab = ['<unk>', '<pad>']\n",
    "\n",
    "# main vocab list, to generate embedding\n",
    "vocab_set = set(custom_vocab + vocab_words['word'].unique().tolist())\n",
    "vocab_size = len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "248af367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6184"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2493caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the vocab\n",
    "word_to_idx = {word:i for i, word in enumerate(vocab_set)}\n",
    "\n",
    "# all the unique tags\n",
    "unique_tags = set(df[\"tag\"].unique())\n",
    "tag_to_idx = {tag:i for i, tag in enumerate(unique_tags)}\n",
    "idx_to_tag = {i:tag for i, tag in enumerate(unique_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbac17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files, group words by sentence, return list of sentences\n",
    "def readData(file):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            sentences.append(sentence.copy())\n",
    "            sentence.clear()\n",
    "        else:\n",
    "            sentence.append(line.strip().split(' '))\n",
    "    # append the last sentence\n",
    "    sentences.append(sentence.copy())\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "88d8db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word = [idx, word, tag]  train_data = list of sentences in term of list of words\n",
    "train_data = readData(train_file)\n",
    "\n",
    "dev_data = readData(dev_file)\n",
    "# word = [idx, word]\n",
    "test_data = readData(test_file)\n",
    "\n",
    "# Dummy test data\n",
    "dummy_file ='data/dummy'\n",
    "dummy_data = readData(dummy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9e757e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preapare training data\n",
    "def processData(tuples):\n",
    "    training_data = []\n",
    "    for t in tuples:\n",
    "        training_data.append( ( [ word[1] if word[1] in word_to_idx else '<unk>' for word in t ], [ word[2] for word in t ] ) )\n",
    "    return training_data\n",
    "\n",
    "# Convert sequence into tensor\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# prepare padded data, return inputs and labels\n",
    "# def processPaddedData(tuples, max_seq_len):\n",
    "#     inputs = []\n",
    "#     labels = []\n",
    "#     PAD = '<pad>'\n",
    "#     for t in tuples:\n",
    "#         seq = [ word[1] if word[1] in word_to_idx else '<unk>' for word in t ]\n",
    "#         # pad seq\n",
    "#         if len(seq) < max_seq_len:\n",
    "#             seq += [ PAD for _ in range(max_seq_len-len(seq)) ]\n",
    "#         inputs.append(seq)\n",
    "#         labels.append( [ word[2] for word in t] )\n",
    "        \n",
    "#     return inputs, labels\n",
    "\n",
    "def processPaddedData(tuples, max_seq_len):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    PAD = '<pad>'\n",
    "    for t in tuples:\n",
    "        seq = [ word[1] if word[1] in word_to_idx else '<unk>' for word in t ]\n",
    "        inputs.append(seq)\n",
    "        labels.append( [ word[2] for word in t] )\n",
    "        \n",
    "    return inputs, labels\n",
    "\n",
    "def seq2idx(inputs, to_ix):\n",
    "    return [ torch.tensor([to_ix[w] for w in seq]) for seq in inputs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a706ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = processData(train_data)\n",
    "max_seq_len = max([ len(sent) for sent, _ in training_data])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ee122112",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = processPaddedData(dummy_data, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4a79c2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([981, 334, 174]), tensor([5778]), tensor([3361, 3361])]\n",
      "tensor([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "unpadded_inputs = seq2idx(inputs, word_to_idx)\n",
    "print(unpadded_inputs)\n",
    "unsort_lengths = t.tensor([len(s) for s in unpadded_inputs])\n",
    "print(unsort_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2cd05e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_idx 3626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 100])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_idx = word_to_idx['<pad>']\n",
    "print(\"padding_idx\", padding_idx)\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "\n",
    "unsort_padded_inputs = pad_sequence(unpadded_inputs, batch_first=True, padding_value=padding_idx)\n",
    "unsort_padded_inputs = embedding(unsort_padded_inputs)\n",
    "unsort_padded_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cfe315be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 1]) tensor([0, 2, 1])\n",
      "unsort_idx tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "sorted_lengths, sorted_len_idx = unsort_lengths.sort(0, descending=True)\n",
    "print(sorted_lengths, sorted_len_idx)\n",
    "_, unsorted_idx = t.sort(sorted_lengths, dim=0)\n",
    "print(\"unsort_idx\", unsorted_idx)\n",
    "\n",
    "a = unsort_padded_inputs[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "433b9666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1548e-01,  4.6567e-01, -5.5241e-01,  1.5951e+00,  1.5188e+00,\n",
       "           6.3830e-01, -6.1782e-01,  6.7159e-01,  1.3609e+00,  1.4467e-02,\n",
       "          -4.4473e-01,  8.5518e-02,  1.9484e-01, -2.4091e+00,  9.4244e-01,\n",
       "           9.6899e-01, -8.1337e-01,  4.4211e-01, -6.1085e-01, -1.1370e+00,\n",
       "           1.3328e+00, -4.6324e-01, -5.0769e-01, -3.4775e-01, -7.6382e-01,\n",
       "          -5.7312e-01,  1.8974e+00,  4.4645e-01,  1.1496e+00, -2.1394e-01,\n",
       "          -9.2324e-01, -9.3872e-01, -1.2094e+00, -8.4744e-01,  2.0133e+00,\n",
       "          -9.8805e-01, -6.7415e-02, -5.6366e-01,  4.5789e-01, -1.5816e-01,\n",
       "           1.2547e+00, -2.1328e+00, -3.5176e-01,  6.9318e-01,  3.4555e-01,\n",
       "           8.3684e-01, -1.1757e-01,  3.4243e-01,  8.8368e-01,  5.8781e-01,\n",
       "           1.7209e-05, -1.2327e+00, -2.0951e-01,  5.3319e-01, -9.1351e-01,\n",
       "           8.3567e-01,  9.0224e-01, -2.2854e-01, -6.6803e-01,  6.3380e-01,\n",
       "           9.7053e-02,  1.3704e-01,  6.3149e-01,  9.7861e-01, -2.1652e-01,\n",
       "          -7.5137e-01,  1.1458e+00,  7.2584e-02, -2.9020e-01, -2.9796e-01,\n",
       "          -2.3659e+00,  1.4444e+00,  7.2384e-01,  5.0928e-01,  9.0302e-01,\n",
       "           2.1795e-01,  2.5283e-01,  6.3471e-01,  2.1010e+00, -4.7766e-01,\n",
       "          -3.6847e-01,  4.0501e-01,  9.8984e-01,  5.7719e-01, -2.1340e+00,\n",
       "           2.1718e+00, -1.0345e+00,  2.3544e+00, -9.8435e-02, -4.7729e-01,\n",
       "          -8.8387e-02, -3.7161e-01, -9.4295e-01, -1.3133e+00, -6.2014e-01,\n",
       "           1.8495e+00, -4.7620e-01,  1.1913e-01, -6.8918e-01,  6.5277e-01],\n",
       "         [ 1.6281e+00,  9.8711e-03,  1.7024e+00, -1.0662e+00,  3.6892e-01,\n",
       "           2.6044e+00, -9.8080e-02, -1.7099e+00,  2.1658e+00,  3.9811e-01,\n",
       "          -7.3729e-01, -7.3832e-01, -1.3475e+00,  4.5401e-01, -6.5232e-01,\n",
       "          -6.3758e-01, -1.1275e+00,  7.2072e-01,  1.1130e-01,  1.7341e+00,\n",
       "          -1.2177e+00,  1.3975e+00,  2.5987e-01, -5.0298e-01,  6.7482e-01,\n",
       "          -9.7887e-01, -1.3537e+00, -2.2375e-02,  4.5103e-01,  1.0985e+00,\n",
       "           1.8485e+00, -5.0525e-01, -3.2199e-01,  1.1420e+00,  1.4442e+00,\n",
       "          -1.2743e+00,  6.6729e-01, -3.8316e-01,  9.1803e-01, -8.5728e-01,\n",
       "           9.7917e-01, -2.2890e-01,  1.4610e+00,  2.6044e-01, -1.5656e+00,\n",
       "          -1.6858e+00,  2.6002e+00, -3.4345e-01, -6.9485e-01,  1.1686e-01,\n",
       "          -1.0631e+00,  3.0732e-01,  2.6155e-01,  2.0612e-01, -1.2526e+00,\n",
       "           1.9942e-01,  8.8312e-01, -3.8552e-01, -6.1113e-02, -1.2909e+00,\n",
       "          -8.0245e-01,  1.5931e+00,  1.1554e+00, -9.2476e-02,  8.2763e-01,\n",
       "           6.1363e-01,  5.8024e-01, -3.0453e-01, -1.4497e-01, -7.1198e-01,\n",
       "           1.4763e-01,  5.0879e-01,  1.0999e+00,  2.0715e-01,  1.2866e+00,\n",
       "          -7.1527e-01,  8.3943e-01, -6.6465e-01,  1.3310e+00,  9.0167e-01,\n",
       "          -1.3600e-01,  2.0171e+00, -7.1277e-01, -3.1892e-01,  3.9391e-01,\n",
       "          -1.1851e-01, -9.1051e-01,  2.2853e-02, -8.3929e-02, -5.4019e-01,\n",
       "          -3.9898e-01,  2.7523e+00, -4.1793e-01, -7.3281e-01, -4.5797e-01,\n",
       "           6.1214e-01, -4.4409e-01,  2.3128e+00, -3.0714e-01,  9.5603e-01],\n",
       "         [ 4.3078e-01,  1.0792e+00, -2.5915e-01, -6.5849e-02, -1.2992e+00,\n",
       "           4.2508e-01, -4.2871e-01,  6.5459e-01, -2.9666e-01,  6.9464e-01,\n",
       "          -3.5514e-01, -1.6983e+00, -1.4167e+00,  4.4983e-01,  3.2811e-01,\n",
       "          -6.9894e-01,  6.8684e-01, -4.7031e-01,  6.0865e-01,  1.3532e+00,\n",
       "           3.2399e-01,  2.3603e-01,  2.1773e-01, -6.0066e-01, -1.0050e+00,\n",
       "          -5.3778e-02, -4.4192e-01,  1.4455e+00, -4.5746e-01, -5.2991e-01,\n",
       "           6.0113e-01,  1.7217e+00,  8.6492e-01, -2.9804e-01, -5.8388e-01,\n",
       "           9.7733e-01,  7.8531e-02,  2.7290e-01,  4.8412e-01, -2.4288e-01,\n",
       "          -3.4042e-01, -8.8764e-01, -6.0852e-01,  7.5382e-01, -7.2116e-01,\n",
       "           3.7501e-01, -2.3661e+00,  4.1864e-04, -1.9022e+00, -2.8400e-01,\n",
       "           4.0863e-01, -9.6139e-01,  6.0835e-01, -8.9942e-02, -1.2186e+00,\n",
       "           8.3742e-01, -7.4375e-01, -1.8026e+00, -1.6866e+00,  7.2874e-01,\n",
       "           1.0969e-01, -1.1332e+00, -7.4782e-01,  2.9926e-01,  2.4864e+00,\n",
       "           9.4745e-01,  6.5354e-01, -6.7401e-01, -1.7429e+00, -3.7589e-01,\n",
       "           6.6641e-01, -4.9026e-01, -2.7586e-01, -7.8155e-01,  4.5487e-01,\n",
       "           3.4958e-02,  8.5384e-01, -1.4962e+00, -1.1309e+00,  3.7120e-01,\n",
       "          -1.4749e+00, -2.0246e-01, -9.2497e-02,  9.6136e-02, -1.9643e+00,\n",
       "          -9.6219e-01,  5.2258e-01,  1.3980e-01, -6.8656e-01, -7.6037e-01,\n",
       "          -1.7998e+00, -8.4125e-01, -2.9097e-01, -1.4313e+00,  1.9725e+00,\n",
       "           5.2789e-02, -7.5210e-01, -5.4162e-01, -1.6785e-01, -3.6395e-02]],\n",
       "\n",
       "        [[ 2.4470e-01, -7.2104e-01,  8.5167e-01, -8.8505e-01,  6.0788e-01,\n",
       "           3.8068e-01,  6.6401e-01, -7.8173e-01, -3.9059e-01,  6.1139e-01,\n",
       "           7.1781e-01, -6.2484e-01, -7.6047e-01, -1.2805e+00,  1.8054e-01,\n",
       "           1.1679e+00,  7.8295e-02, -1.2565e+00, -7.2410e-01,  9.8366e-01,\n",
       "          -9.2216e-01, -1.5207e+00,  6.3628e-01, -9.8686e-01, -3.3061e-01,\n",
       "          -3.1111e-01,  2.5003e-01, -5.3717e-01,  1.2958e+00, -1.6814e+00,\n",
       "           5.0677e-01, -1.6441e+00,  1.0225e+00,  1.2378e+00,  5.8596e-02,\n",
       "           8.3060e-01,  1.6918e+00,  7.1534e-01, -1.5637e+00,  1.3519e+00,\n",
       "           1.3032e+00, -1.0459e+00,  4.3574e-01, -2.7303e+00,  3.0152e-01,\n",
       "          -1.0862e+00,  1.6787e+00,  3.9249e-01, -2.5072e-01,  1.0888e+00,\n",
       "           1.5271e+00, -5.0837e-02, -1.5828e-01,  2.1596e+00, -1.4636e+00,\n",
       "          -1.3196e+00, -1.1515e+00, -6.1701e-01,  1.1513e+00,  8.3856e-01,\n",
       "          -2.4098e-01,  1.8410e+00,  2.4612e+00, -4.3052e-01,  5.8919e-01,\n",
       "          -3.9604e-01, -1.5597e-01,  5.6721e-01, -1.4664e+00, -1.6959e-02,\n",
       "          -1.5323e+00,  2.2131e+00, -4.0543e-01, -1.1118e+00, -2.1772e-01,\n",
       "           1.8535e+00,  1.1547e+00, -4.1042e-01, -1.8255e-01,  2.5627e-01,\n",
       "           3.6953e-01, -9.8063e-01, -2.0500e-01, -4.0372e-01, -1.0256e+00,\n",
       "          -5.7010e-02, -6.2901e-01, -6.8314e-01,  1.6601e+00,  3.6764e-01,\n",
       "          -1.1135e-02,  4.8394e-01, -1.1343e+00, -8.9604e-01,  2.9128e-01,\n",
       "          -1.5231e-01, -5.3640e-01, -3.3994e-01, -6.5793e-01,  1.0403e-02],\n",
       "         [ 2.4470e-01, -7.2104e-01,  8.5167e-01, -8.8505e-01,  6.0788e-01,\n",
       "           3.8068e-01,  6.6401e-01, -7.8173e-01, -3.9059e-01,  6.1139e-01,\n",
       "           7.1781e-01, -6.2484e-01, -7.6047e-01, -1.2805e+00,  1.8054e-01,\n",
       "           1.1679e+00,  7.8295e-02, -1.2565e+00, -7.2410e-01,  9.8366e-01,\n",
       "          -9.2216e-01, -1.5207e+00,  6.3628e-01, -9.8686e-01, -3.3061e-01,\n",
       "          -3.1111e-01,  2.5003e-01, -5.3717e-01,  1.2958e+00, -1.6814e+00,\n",
       "           5.0677e-01, -1.6441e+00,  1.0225e+00,  1.2378e+00,  5.8596e-02,\n",
       "           8.3060e-01,  1.6918e+00,  7.1534e-01, -1.5637e+00,  1.3519e+00,\n",
       "           1.3032e+00, -1.0459e+00,  4.3574e-01, -2.7303e+00,  3.0152e-01,\n",
       "          -1.0862e+00,  1.6787e+00,  3.9249e-01, -2.5072e-01,  1.0888e+00,\n",
       "           1.5271e+00, -5.0837e-02, -1.5828e-01,  2.1596e+00, -1.4636e+00,\n",
       "          -1.3196e+00, -1.1515e+00, -6.1701e-01,  1.1513e+00,  8.3856e-01,\n",
       "          -2.4098e-01,  1.8410e+00,  2.4612e+00, -4.3052e-01,  5.8919e-01,\n",
       "          -3.9604e-01, -1.5597e-01,  5.6721e-01, -1.4664e+00, -1.6959e-02,\n",
       "          -1.5323e+00,  2.2131e+00, -4.0543e-01, -1.1118e+00, -2.1772e-01,\n",
       "           1.8535e+00,  1.1547e+00, -4.1042e-01, -1.8255e-01,  2.5627e-01,\n",
       "           3.6953e-01, -9.8063e-01, -2.0500e-01, -4.0372e-01, -1.0256e+00,\n",
       "          -5.7010e-02, -6.2901e-01, -6.8314e-01,  1.6601e+00,  3.6764e-01,\n",
       "          -1.1135e-02,  4.8394e-01, -1.1343e+00, -8.9604e-01,  2.9128e-01,\n",
       "          -1.5231e-01, -5.3640e-01, -3.3994e-01, -6.5793e-01,  1.0403e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-5.3115e-01, -1.1869e+00,  6.0092e-01, -2.3874e+00,  7.7276e-01,\n",
       "           1.7757e-01,  4.4460e-01,  1.2998e+00, -2.2297e-01,  1.8819e+00,\n",
       "          -9.1455e-02, -1.2331e+00, -5.1483e-01, -1.7160e+00,  4.5749e-01,\n",
       "          -4.0480e-01, -2.0692e+00,  1.5886e+00,  2.7688e+00,  6.6324e-01,\n",
       "           4.8551e-01, -6.5939e-01, -1.3812e+00, -8.3333e-01,  5.5761e-01,\n",
       "          -1.1458e+00,  4.3902e-01,  7.9160e-01, -1.4774e-01,  1.8834e-01,\n",
       "           1.6168e+00, -8.7386e-01, -1.0957e+00,  7.2105e-02, -2.2840e+00,\n",
       "           2.6330e-01,  4.6858e-01,  8.3697e-01, -5.1603e-01, -1.1550e-01,\n",
       "          -9.4905e-01,  1.0773e+00, -9.5102e-01, -3.1097e-02,  1.5084e+00,\n",
       "          -2.7872e-01,  1.8381e+00,  2.4795e+00,  7.4474e-01,  4.5307e-02,\n",
       "           1.0817e+00, -7.1728e-01, -3.3118e-01, -1.3878e+00,  6.1189e-01,\n",
       "          -4.2391e-01,  1.7670e+00, -7.2446e-01,  4.9265e-01, -2.4504e-01,\n",
       "          -3.5103e-01, -8.6775e-01,  1.2085e+00, -5.1451e-01, -4.7786e-01,\n",
       "           6.3070e-01,  7.4619e-01, -2.8324e-01, -1.2629e+00,  1.1886e+00,\n",
       "          -4.9845e-01, -1.2466e+00, -9.3217e-01, -1.2754e+00,  5.5012e-01,\n",
       "           9.2729e-02, -2.0612e-01, -2.1526e-01, -1.1059e+00, -3.0286e-01,\n",
       "           2.2466e-01,  6.2740e-01, -8.0040e-02, -8.8489e-01, -5.4360e-01,\n",
       "          -1.8032e+00,  7.2952e-01,  1.1671e+00, -2.3281e+00, -1.5449e+00,\n",
       "           2.3621e-01,  1.3258e+00, -2.6631e+00, -1.3776e+00, -6.4328e-01,\n",
       "          -4.7068e-01,  3.8714e-01,  2.1242e-01,  4.5320e-01,  9.6487e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7224a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 113, 100])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = embedding(b)\n",
    "b.shape # batch=3, seq=113, dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cefa6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = seq2idx(inputs, word_to_idx)\n",
    "labels = seq2idx(labels, tag_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77a7b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(1000, max_len, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3809202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 113, 100])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape\n",
    "#[batch, seq, dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6585f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "952d2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = processData(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ef93632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "vocab_size = len(word_to_idx)\n",
    "tagset_size = len(tag_to_idx)\n",
    "\n",
    "lstm_layer = 1\n",
    "lstm_dropout = 0.33\n",
    "linear_out_dim = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "1b0967c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "    \n",
    "    # sentence [seq, batch, embed_dim]\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1c5963d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, linear_out_dim, lstm_layer, lstm_dropout):\n",
    "        super(BLSTM, self).__init__()\n",
    "        # word embedding\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            bidirectional=True)\n",
    "        self.linear = nn.Linear(2*hidden_dim,linear_out_dim)\n",
    "        self.fc = nn.Linear(linear_out_dim, tagset_size)\n",
    "        self.dropout = nn.Dropout(lstm_dropout)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        # Embedding layer + LSTM input dropout\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        embeds = self.dropout(embeds)\n",
    "        # BLSTM layer + LSTM output dropout\n",
    "        lstm_out, _ = self.bilstm(embeds.view(len(sentence), 1, -1))\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        # Linear layer + elu\n",
    "        linear_out = F.elu(self.linear(lstm_out.view(len(sentence), -1)))\n",
    "        # classifier\n",
    "        tag_space = self.fc(linear_out)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9b644cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "lr = 0.1\n",
    "epochs = 10\n",
    "print_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fc803e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(embedding_dim, hidden_dim, vocab_size, tagset_size).to(device)\n",
    "# model = BLSTM(embedding_dim, hidden_dim, vocab_size, tagset_size, linear_out_dim, lstm_layer, lstm_dropout).to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "154b6343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMTagger(\n",
       "  (word_embeddings): Embedding(4148, 100)\n",
       "  (lstm): LSTM(100, 256)\n",
       "  (hidden2tag): Linear(in_features=256, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd71895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-MISC', 'I-ORG', 'I-ORG', 'I-LOC', 'B-PER', 'I-ORG', 'I-ORG', 'I-ORG', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:25<00:00, 576.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:25<00:00, 582.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.1059e-05, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14987/14987 [00:26<00:00, 556.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6212e-05, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 3655/14987 [00:06<00:19, 575.89it/s]"
     ]
    }
   ],
   "source": [
    "# Before training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_idx).to(device)\n",
    "    tag_scores = model(inputs)\n",
    "    print([idx_to_tag[i] for i in torch.argmax(tag_scores, dim=1).tolist()])\n",
    "\n",
    "\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    for sentence, tags in tqdm(training_data, total=len(training_data)):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        sentence_in = prepare_sequence(sentence, word_to_idx).to(device)\n",
    "        targets = prepare_sequence(tags, tag_to_idx).to(device)\n",
    "        \n",
    "        tag_scores = model(sentence_in)\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%print_every == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    \n",
    "# After training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_idx).to(device)\n",
    "    tag_scores = model(inputs)\n",
    "    print([idx_to_tag[i] for i in torch.argmax(tag_scores, dim=1).tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEvalFile(model, input_data, file_name):\n",
    "    # Reset the file\n",
    "    open(file_name, 'w').close()\n",
    "    f = open(file_name, \"a\")\n",
    "    \n",
    "    # model eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    for sentence, tags in input_data:\n",
    "        idx = 1\n",
    "        with torch.no_grad():\n",
    "            inputs = prepare_sequence(sentence, word_to_idx).to(device)\n",
    "            tag_scores = model(inputs) \n",
    "            preds = [idx_to_tag[i] for i in torch.argmax(tag_scores, dim=1).tolist()]\n",
    "            for word, gold, pred in zip(sentence, tags, preds):\n",
    "                f.write(f'{idx} {word} {gold} {pred}\\n')\n",
    "                idx+=1\n",
    "            f.write('\\n')      \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"blstm_t3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db365210",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input = processData(dev_data)\n",
    "generateEvalFile(model, dev_input, f\"{model_name}_eval.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"{model_name}.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# Load\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
