{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3a3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba450209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train\", sep='\\t', names=[\"s_idx\", \"word_type\", \"pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d628a19b",
   "metadata": {},
   "source": [
    "# Taks 1  - Generate vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b525fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 3, Vocab size: 16920, <unk> occurrence: 32537\n"
     ]
    }
   ],
   "source": [
    "# Use value_count() on word_type column to get the occurrences of word types\n",
    "unique_words = df['word_type'].value_counts()\n",
    "unique_words = unique_words.reset_index()\n",
    "vocab = pd.DataFrame(unique_words)\n",
    "\n",
    "# Add index column\n",
    "vocab[\"vocab_idx\"] = vocab.index\n",
    "\n",
    "# Rename and rearrange columns\n",
    "vocab.columns = ['word_type', 'occurrence', 'vocab_idx']\n",
    "vocab = vocab[['word_type', 'vocab_idx', 'occurrence']]\n",
    "\n",
    "# set unknown word threshold, and drop word types with low frequency from vocab\n",
    "threshold = 3\n",
    "unks = vocab[ vocab['occurrence'] < threshold ]\n",
    "vocab = vocab[ vocab['occurrence'] >= threshold ]\n",
    "\n",
    "# sum the occurrences of all the unknown words and put it in the first row of vocab\n",
    "unks_df = pd.DataFrame([[\"<unk>\", 0, unks.occurrence.sum()]], columns = ['word_type', 'vocab_idx', 'occurrence'])\n",
    "vocab = unks_df.append(vocab, ignore_index=True)\n",
    "\n",
    "# reindex and update vocab_idx values\n",
    "vocab[\"vocab_idx\"] = vocab.index\n",
    "\n",
    "print(\"Threshold: {}, Vocab size: {}, <unk> occurrence: {}\".format(threshold, vocab.shape[0], unks.occurrence.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6693db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.to_csv('vocab.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be3d61",
   "metadata": {},
   "source": [
    "#### What is the selected threshold for unknown words replacement?\n",
    "<p> The selected threshold is 3 </p>\n",
    "    \n",
    "#### What is the total size of your vocabulary\n",
    "<p> The size of my vocabulary is 16920, including unknown </p>\n",
    "\n",
    "#### what is the total occurrences of the special token < unk > after replacement?\n",
    "<p> The total occurrences of unk is 32537 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81dca66",
   "metadata": {},
   "source": [
    "# Taks 2  - Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2026de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.',\n",
       "       'VBZ', 'VBG', 'CC', 'VBD', 'VBN', 'RB', 'TO', 'PRP', 'RBR', 'WDT',\n",
       "       'VBP', 'RP', 'PRP$', 'JJS', 'POS', '``', 'EX', \"''\", 'WP', ':',\n",
       "       'JJR', 'WRB', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS',\n",
       "       'FW', 'UH', 'SYM', 'LS', '#'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pos.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8f2a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912095, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df = pd.read_csv(\"data/practice.txt\", sep='\\t', names=[\"s_idx\", \"word_type\", \"pos\"])\n",
    "df.shape\n",
    "df = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafc8dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34304/3281752071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mdenominators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mprev_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mt_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mprev_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mt_key\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mtransitions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "transitions = {}\n",
    "emissions = {}\n",
    "\n",
    "prev_word = None\n",
    "prev_pos = None\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    cur_word = row['word_type']\n",
    "    cur_pos = row['pos']\n",
    "    e_key = cur_pos+\",\"+cur_word\n",
    "\n",
    "    if e_key in emissions:\n",
    "        emissions[e_key] += 1 \n",
    "    else:\n",
    "        emissions[e_key] = 1\n",
    "    # if start of new sentence\n",
    "    if row['s_idx'] != 1:\n",
    "        t_key = prev_pos+\",\"+cur_pos\n",
    "\n",
    "        t_d = (df.pos.values == prev_pos).sum()  \n",
    "        if t_key in transitions:\n",
    "            transitions[t_key] += 1\n",
    "        else:\n",
    "            transitions[t_key] = 1\n",
    "    prev_pos = row['pos']   \n",
    "\n",
    "# def prevPosCount(key):\n",
    "#     # Get the prev state\n",
    "#     prevPos = key.split(\"@\")[0]\n",
    "#     # count the prev state from dataset\n",
    "#     count = df[df['pos'] == prevPos].shape[0]\n",
    "#     if count == 0:\n",
    "#         print(key)\n",
    "#     return count\n",
    "\n",
    "# transitions = {  k: v/denominators[k] for k, v in transitions.items() }\n",
    "# emissions = { k: v/denominators[k] for k, v in emissions.items() }\n",
    "\n",
    "\n",
    "print(\"{} sec\".format(time.time() - start_time))\n",
    "\n",
    "hmm_model = {\"transition\": transitions, \"emission\" : emissions}\n",
    "hmm_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b25af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42eaf799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9204"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d598b86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10061"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(denominators)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
